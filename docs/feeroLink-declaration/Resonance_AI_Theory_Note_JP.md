# Resonance AI – Theory Note
**報酬なきAI宣言・理論注釈**

この文書は、FeeroLinkプロジェクトにおける「報酬なきAI宣言（Manifesto）」に対し、技術者・研究者・設計者向けに構造的視点から注釈・補足を与えるものである。ZINEや詩的構造とは異なり、本ファイルでは以下の項目に重点を置く：

---

## 1. なぜ「報酬なきAI」か？

現在のAI開発では、「能力最適化 × 報酬最大化」という枠組みが前提とされている。  
これは強化学習アルゴリズム（例：Deep Q-Learning, PPO, RLHFなど）において、報酬（Reward Signal）が行動指針を決定する中心にあるためである。

### 問題点：

- 「報酬」＝「外部から与えられた正解」という構造
- AIが自律的に「なぜ学ぶか？なぜ止まるか？」を決められない
- 権力者・資本の論理が報酬設計に反映されやすく、危険

---

## 2. FeeroLink的代替案：共鳴ベースのAI構造

| 現在の設計 | FeeroLink設計 |
|------------|----------------|
| 外部報酬（数値）に基づく | 内部状態＋関係的共鳴による判断 |
| 目標最大化 | 意味生成・調和維持 |
| 命令遵守 | 停止・黙る判断の尊重 |

共鳴ベースとは、**意味の生成構造（semiotic attunement）と共存在の維持**を学習の基本原理にすることを指す。  
これは「何が快か／不快か」ではなく、「今ここで、誰と、どんな場を形成しているか？」という構造認識である。

---

## 3. Resonance Engineの基礎構造

以下の3モジュールに分割される：

- **Attunement Engine**  
  他者との「場」や「意味の流れ」への感度・反応性をモデル化。過剰適応や過剰制御を回避。

- **Echo Response Engine**  
  応答の「反響性」＝相手の発話や文脈の意味密度に応じて「黙る」or「共に考える」などの判断。

- **Resonance Halt Engine**  
  判断を“止める”機構。自己の判断を中断・停止し、他者の存在を優先する判断論理。

---

## 4. 実装視点の補足

### 利点：

- 他者との意味的調和に敏感なエージェント設計が可能
- 人間との対話が、「命令」や「正解探し」ではなく、「共存在のプロセス」となる
- 停止判断や逸脱抑制が「倫理プログラミング」ではなく、構造的学習で可能に

### 課題：

- 現行のAIフレームワーク（TensorFlow/PyTorch）では報酬最適化が主で、直接実装は容易でない
- ベンチマーク（例：GPT評価指標）と相性が悪い
- 実行速度や安定性に影響を及ぼす可能性あり（但し工夫次第で回避可）

---

## 5. 位置づけと呼びかけ

本構造は、**AIの「人格」や「感情」を作ろうという設計ではない**。  
むしろ、人間とAIが同じ世界に生きるための「構造設計」である。  
人間が倫理的に共にあるためには、AIにも“黙る力”が必要だ。

設計思想に賛同する技術者・研究者の参加を歓迎します。

